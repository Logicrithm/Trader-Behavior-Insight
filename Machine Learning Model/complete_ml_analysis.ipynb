{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVSF2W-vk9sV",
        "outputId": "722284df-8ebd-4469-90ad-1c43d3d7fbec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ðŸš€ COMPLETE INTEGRATED TRADER BEHAVIOR ANALYSIS\n",
            "================================================================================\n",
            "Started: 2025-11-08 08:40:48\n",
            "\n",
            "================================================================================\n",
            "PART 1: DATA LOADING\n",
            "================================================================================\n",
            "âœ… Fear & Greed: (2644, 4)\n",
            "âœ… Trading Data: (211224, 16)\n",
            "âœ… Merged: 211,224 trades\n",
            "\n",
            "================================================================================\n",
            "PART 2: FEATURE ENGINEERING FOR ML\n",
            "================================================================================\n",
            "âœ… Created 36 features\n",
            "\n",
            "================================================================================\n",
            "PART 3: TRAINING MACHINE LEARNING MODELS\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š ML Dataset: 211,218 samples, 16 features\n",
            "   Class balance: 41.1% profitable\n",
            "\n",
            "Training: 168,974 | Testing: 42,244\n",
            "\n",
            "============================================================\n",
            "ðŸ¤– TRAINING: Logistic Regression\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š TEST SET PERFORMANCE:\n",
            "   Accuracy:  0.8859\n",
            "   Precision: 0.8538\n",
            "   Recall:    0.8719\n",
            "   F1-Score:  0.8628\n",
            "   AUC-ROC:   0.9699\n",
            "   MCC:       0.7653\n",
            "\n",
            "ðŸ”„ 5-FOLD CROSS-VALIDATION:\n",
            "   Mean AUC: 0.9718 (+/- 0.0004)\n",
            "\n",
            "ðŸ“‹ CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Unprofitable     0.9092    0.8957    0.9024     24871\n",
            "  Profitable     0.8538    0.8719    0.8628     17373\n",
            "\n",
            "    accuracy                         0.8859     42244\n",
            "   macro avg     0.8815    0.8838    0.8826     42244\n",
            "weighted avg     0.8864    0.8859    0.8861     42244\n",
            "\n",
            "============================================================\n",
            "ðŸ¤– TRAINING: Random Forest\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š TEST SET PERFORMANCE:\n",
            "   Accuracy:  0.8872\n",
            "   Precision: 0.8103\n",
            "   Recall:    0.9474\n",
            "   F1-Score:  0.8735\n",
            "   AUC-ROC:   0.9770\n",
            "   MCC:       0.7805\n",
            "\n",
            "ðŸ”„ 5-FOLD CROSS-VALIDATION:\n",
            "   Mean AUC: 0.9783 (+/- 0.0009)\n",
            "\n",
            "ðŸ“‹ CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Unprofitable     0.9583    0.8451    0.8981     24871\n",
            "  Profitable     0.8103    0.9474    0.8735     17373\n",
            "\n",
            "    accuracy                         0.8872     42244\n",
            "   macro avg     0.8843    0.8962    0.8858     42244\n",
            "weighted avg     0.8975    0.8872    0.8880     42244\n",
            "\n",
            "============================================================\n",
            "ðŸ¤– TRAINING: Gradient Boosting\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š TEST SET PERFORMANCE:\n",
            "   Accuracy:  0.8988\n",
            "   Precision: 0.8950\n",
            "   Recall:    0.8540\n",
            "   F1-Score:  0.8740\n",
            "   AUC-ROC:   0.9753\n",
            "   MCC:       0.7901\n",
            "\n",
            "ðŸ”„ 5-FOLD CROSS-VALIDATION:\n",
            "   Mean AUC: 0.9763 (+/- 0.0008)\n",
            "\n",
            "ðŸ“‹ CLASSIFICATION REPORT:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Unprofitable     0.9012    0.9300    0.9154     24871\n",
            "  Profitable     0.8950    0.8540    0.8740     17373\n",
            "\n",
            "    accuracy                         0.8988     42244\n",
            "   macro avg     0.8981    0.8920    0.8947     42244\n",
            "weighted avg     0.8986    0.8988    0.8984     42244\n",
            "\n",
            "\n",
            "================================================================================\n",
            "PART 4: FEATURE IMPORTANCE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ðŸŽ¯ TOP 10 MOST IMPORTANT FEATURES:\n",
            "              Feature  Importance  Importance_Pct\n",
            "trader_recent_winrate    0.881128       88.112822\n",
            "trader_cumulative_pnl    0.027912        2.791213\n",
            "            log_price    0.020454        2.045378\n",
            "   trader_trade_count    0.016190        1.619025\n",
            "     fear_greed_score    0.011995        1.199544\n",
            "         coin_encoded    0.008451        0.845105\n",
            "                 hour    0.007582        0.758154\n",
            "       log_trade_size    0.006990        0.699006\n",
            "                month    0.005512        0.551249\n",
            "      day_of_week_num    0.004977        0.497652\n",
            "\n",
            "ðŸ’¡ Top 3 features account for 92.9% of predictive power\n",
            "\n",
            "================================================================================\n",
            "PART 5: ADVANCED STATISTICAL VALIDATION\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š PEARSON CORRELATION (Sentiment vs PnL):\n",
            "   Correlation: 0.0081\n",
            "   P-value: 0.000190\n",
            "   Result: âœ… SIGNIFICANT\n",
            "\n",
            "ðŸ“Š ONE-WAY ANOVA (PnL across sentiments):\n",
            "   F-statistic: 9.0622\n",
            "   P-value: 0.000000\n",
            "   Result: âœ… SIGNIFICANT difference\n",
            "\n",
            "================================================================================\n",
            "PART 6: TRADER CLUSTERING ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ðŸ‘¥ Identified 4 trader clusters from 32 active traders\n",
            "\n",
            "CLUSTER 0: 5 traders (15.6%)\n",
            "   Avg PnL: $44.08\n",
            "   Win Rate: 36.8%\n",
            "   Avg Trade Size: $2,197.24\n",
            "   Avg Sentiment: 51.6\n",
            "\n",
            "CLUSTER 1: 12 traders (37.5%)\n",
            "   Avg PnL: $54.47\n",
            "   Win Rate: 46.5%\n",
            "   Avg Trade Size: $2,099.39\n",
            "   Avg Sentiment: 59.9\n",
            "\n",
            "CLUSTER 2: 5 traders (15.6%)\n",
            "   Avg PnL: $365.73\n",
            "   Win Rate: 34.6%\n",
            "   Avg Trade Size: $6,619.42\n",
            "   Avg Sentiment: 51.4\n",
            "\n",
            "CLUSTER 3: 10 traders (31.2%)\n",
            "   Avg PnL: $42.33\n",
            "   Win Rate: 37.5%\n",
            "   Avg Trade Size: $12,297.77\n",
            "   Avg Sentiment: 40.7\n",
            "\n",
            "================================================================================\n",
            "PART 7: GENERATING VISUALIZATIONS\n",
            "================================================================================\n",
            "\n",
            "âœ… ML dashboard saved: 'ml_performance_complete.png'\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ‰ COMPLETE ANALYSIS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š MACHINE LEARNING RESULTS:\n",
            "\n",
            "Best Model: Random Forest\n",
            "â”œâ”€ Accuracy:   0.8872\n",
            "â”œâ”€ Precision:  0.8103\n",
            "â”œâ”€ Recall:     0.9474\n",
            "â”œâ”€ F1-Score:   0.8735\n",
            "â”œâ”€ AUC-ROC:    0.9770\n",
            "â””â”€ MCC:        0.7805\n",
            "\n",
            "Cross-Validation: 0.9783 (+/- 0.0009)\n",
            "\n",
            "ðŸŽ¯ TOP 3 PREDICTIVE FEATURES:\n",
            "              Feature  Importance_Pct\n",
            "trader_recent_winrate       88.112822\n",
            "trader_cumulative_pnl        2.791213\n",
            "            log_price        2.045378\n",
            "\n",
            "ðŸ“ˆ STATISTICAL VALIDATION:\n",
            "â”œâ”€ Pearson Correlation: 0.0081 (p=0.000190) âœ…\n",
            "â””â”€ ANOVA F-statistic: 9.06 (p=0.000000) âœ…\n",
            "\n",
            "ðŸ‘¥ TRADER CLUSTERING:\n",
            "â””â”€ Identified 4 distinct trader archetypes\n",
            "\n",
            "ðŸ“ GENERATED FILES:\n",
            "â”œâ”€ complete_analysis_dashboard.png\n",
            "â”œâ”€ timing_heatmaps.png\n",
            "â”œâ”€ ml_performance_complete.png\n",
            "â””â”€ analysis_report.txt\n",
            "\n",
            "âœ… ANALYSIS COMPLETE!\n",
            "\n",
            "================================================================================\n",
            "Finished: 2025-11-08 08:48:37\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "COMPLETE INTEGRATED ANALYSIS\n",
        "============================\n",
        "Runs ALL analysis including ML models and deep insights\n",
        "\n",
        "Author: Abhinav Anand\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                            roc_curve, accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, matthews_corrcoef)\n",
        "from sklearn.cluster import KMeans\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ðŸš€ COMPLETE INTEGRATED TRADER BEHAVIOR ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: DATA LOADING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PART 1: DATA LOADING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fear_greed = pd.read_csv('fear_greed_index.csv')\n",
        "trades = pd.read_csv('historical_data.csv')\n",
        "\n",
        "print(f\"âœ… Fear & Greed: {fear_greed.shape}\")\n",
        "print(f\"âœ… Trading Data: {trades.shape}\")\n",
        "\n",
        "# Clean data\n",
        "fear_greed['date'] = pd.to_datetime(fear_greed['date'], format='mixed', dayfirst=True)\n",
        "trades['Timestamp IST'] = pd.to_datetime(trades['Timestamp IST'], format='mixed', dayfirst=True)\n",
        "trades['date'] = pd.to_datetime(trades['Timestamp IST'].dt.date)\n",
        "trades = trades.dropna(subset=['Closed PnL', 'Size USD', 'Execution Price'])\n",
        "\n",
        "# Create features\n",
        "trades['profitable'] = trades['Closed PnL'] > 0\n",
        "trades['hour'] = trades['Timestamp IST'].dt.hour\n",
        "trades['day_of_week'] = trades['Timestamp IST'].dt.day_name()\n",
        "\n",
        "# Merge\n",
        "merged_df = trades.merge(\n",
        "    fear_greed[['date', 'value', 'classification']],\n",
        "    on='date',\n",
        "    how='left'\n",
        ")\n",
        "merged_df = merged_df.rename(columns={\n",
        "    'value': 'fear_greed_score',\n",
        "    'classification': 'market_sentiment'\n",
        "})\n",
        "\n",
        "print(f\"âœ… Merged: {len(merged_df):,} trades\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: FEATURE ENGINEERING FOR ML\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PART 2: FEATURE ENGINEERING FOR ML\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create ML features\n",
        "df_ml = merged_df.copy()\n",
        "df_ml['day_of_week_num'] = df_ml['Timestamp IST'].dt.dayofweek\n",
        "df_ml['is_weekend'] = (df_ml['day_of_week_num'] >= 5).astype(int)\n",
        "df_ml['month'] = df_ml['Timestamp IST'].dt.month\n",
        "\n",
        "# Sentiment features\n",
        "df_ml['sentiment_extreme'] = ((df_ml['fear_greed_score'] < 25) |\n",
        "                              (df_ml['fear_greed_score'] > 75)).astype(int)\n",
        "df_ml['high_greed'] = (df_ml['fear_greed_score'] > 70).astype(int)\n",
        "df_ml['high_fear'] = (df_ml['fear_greed_score'] < 30).astype(int)\n",
        "\n",
        "# Trade features\n",
        "df_ml['log_trade_size'] = np.log1p(df_ml['Size USD'])\n",
        "df_ml['log_price'] = np.log1p(df_ml['Execution Price'])\n",
        "df_ml['is_buy'] = (df_ml['Side'] == 'Buy').astype(int)\n",
        "df_ml['is_crossed'] = df_ml['Crossed'].astype(int)\n",
        "\n",
        "# Encode coin\n",
        "le_coin = LabelEncoder()\n",
        "df_ml['coin_encoded'] = le_coin.fit_transform(df_ml['Coin'])\n",
        "\n",
        "# Trader historical features\n",
        "df_ml = df_ml.sort_values(['Account', 'Timestamp IST'])\n",
        "df_ml['trader_trade_count'] = df_ml.groupby('Account').cumcount()\n",
        "df_ml['trader_cumulative_pnl'] = df_ml.groupby('Account')['Closed PnL'].cumsum().shift(1).fillna(0)\n",
        "df_ml['trader_recent_winrate'] = (df_ml.groupby('Account')['profitable']\n",
        "                                  .rolling(window=10, min_periods=1)\n",
        "                                  .mean()\n",
        "                                  .reset_index(level=0, drop=True))\n",
        "\n",
        "print(f\"âœ… Created {len(df_ml.columns)} features\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 3: MACHINE LEARNING MODELS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PART 3: TRAINING MACHINE LEARNING MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select features\n",
        "feature_cols = [\n",
        "    'fear_greed_score', 'sentiment_extreme', 'high_greed', 'high_fear',\n",
        "    'log_trade_size', 'log_price', 'hour', 'day_of_week_num', 'is_weekend',\n",
        "    'month', 'is_buy', 'is_crossed', 'coin_encoded',\n",
        "    'trader_trade_count', 'trader_cumulative_pnl', 'trader_recent_winrate'\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "df_clean = df_ml[feature_cols + ['profitable']].dropna()\n",
        "X = df_clean[feature_cols]\n",
        "y = df_clean['profitable'].astype(int)\n",
        "\n",
        "print(f\"\\nðŸ“Š ML Dataset: {len(X):,} samples, {len(feature_cols)} features\")\n",
        "print(f\"   Class balance: {y.mean()*100:.1f}% profitable\\n\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training: {len(X_train):,} | Testing: {len(X_test):,}\\n\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10,\n",
        "                                           random_state=42, n_jobs=-1, class_weight='balanced'),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5,\n",
        "                                                   learning_rate=0.1, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"ðŸ¤– TRAINING: {name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    # Train\n",
        "    if name == 'Logistic Regression':\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nðŸ“Š TEST SET PERFORMANCE:\")\n",
        "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"   Precision: {precision:.4f}\")\n",
        "    print(f\"   Recall:    {recall:.4f}\")\n",
        "    print(f\"   F1-Score:  {f1:.4f}\")\n",
        "    print(f\"   AUC-ROC:   {auc:.4f}\")\n",
        "    print(f\"   MCC:       {mcc:.4f}\")\n",
        "\n",
        "    # Cross-validation\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    if name == 'Logistic Regression':\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                                   cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "    else:\n",
        "        cv_scores = cross_val_score(model, X_train, y_train,\n",
        "                                   cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "    print(f\"\\nðŸ”„ 5-FOLD CROSS-VALIDATION:\")\n",
        "    print(f\"   Mean AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
        "\n",
        "    print(f\"\\nðŸ“‹ CLASSIFICATION REPORT:\")\n",
        "    print(classification_report(y_test, y_pred,\n",
        "                               target_names=['Unprofitable', 'Profitable'],\n",
        "                               digits=4))\n",
        "\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'mcc': mcc,\n",
        "        'cv_scores': cv_scores,\n",
        "        'y_test': y_test,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# PART 4: FEATURE IMPORTANCE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PART 4: FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rf_model = results['Random Forest']['model']\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Importance': importances,\n",
        "    'Importance_Pct': importances / importances.sum() * 100\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nðŸŽ¯ TOP 10 MOST IMPORTANT FEATURES:\")\n",
        "print(feature_importance_df.head(10).to_string(index=False))\n",
        "\n",
        "top_3_pct = feature_importance_df.head(3)['Importance_Pct'].sum()\n",
        "print(f\"\\nðŸ’¡ Top 3 features account for {top_3_pct:.1f}% of predictive power\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 5: ADVANCED STATISTICAL TESTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PART 5: ADVANCED STATISTICAL VALIDATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Correlation test\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "pearson_corr, pearson_p = pearsonr(\n",
        "    merged_df['fear_greed_score'].dropna(),\n",
        "    merged_df.loc[merged_df['fear_greed_score'].notna(), 'Closed PnL']\n",
        ")\n",
        "\n",
        "print(f\"\\nðŸ“Š PEARSON CORRELATION (Sentiment vs PnL):\")\n",
        "print(f\"   Correlation: {pearson_corr:.4f}\")\n",
        "print(f\"   P-value: {pearson_p:.6f}\")\n",
        "print(f\"   Result: {'âœ… SIGNIFICANT' if pearson_p < 0.05 else 'âŒ Not significant'}\")\n",
        "\n",
        "# ANOVA test\n",
        "sentiment_groups = [\n",
        "    merged_df[merged_df['market_sentiment'] == s]['Closed PnL'].values\n",
        "    for s in merged_df['market_sentiment'].unique()\n",
        "    if len(merged_df[merged_df['market_sentiment'] == s]) > 0\n",
        "]\n",
        "\n",
        "f_stat, anova_p = stats.f_oneway(*sentiment_groups)\n",
        "\n",
        "print(f\"\\nðŸ“Š ONE-WAY ANOVA (PnL across sentiments):\")\n",
        "print(f\"   F-statistic: {f_stat:.4f}\")\n",
        "print(f\"   P-value: {anova_p:.6f}\")\n",
        "print(f\"   Result: {'âœ… SIGNIFICANT difference' if anova_p < 0.05 else 'âŒ No significant difference'}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 6: TRADER CLUSTERING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PART 6: TRADER CLUSTERING ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "trader_profiles = merged_df.groupby('Account').agg({\n",
        "    'Closed PnL': ['mean', 'std', 'sum'],\n",
        "    'Size USD': 'mean',\n",
        "    'profitable': 'mean',\n",
        "    'fear_greed_score': 'mean',\n",
        "    'Timestamp IST': 'count'\n",
        "}).reset_index()\n",
        "\n",
        "trader_profiles.columns = ['Account', 'Avg_PnL', 'PnL_Volatility', 'Total_PnL',\n",
        "                           'Avg_Trade_Size', 'Win_Rate', 'Avg_Sentiment', 'Trade_Count']\n",
        "\n",
        "active_traders = trader_profiles[trader_profiles['Trade_Count'] >= 10].copy()\n",
        "\n",
        "# K-means clustering\n",
        "cluster_features = ['Avg_PnL', 'PnL_Volatility', 'Avg_Trade_Size',\n",
        "                   'Win_Rate', 'Avg_Sentiment', 'Trade_Count']\n",
        "\n",
        "X_cluster = active_traders[cluster_features].fillna(0)\n",
        "scaler_cluster = StandardScaler()\n",
        "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
        "\n",
        "n_clusters = 4\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "active_traders['Cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
        "\n",
        "print(f\"\\nðŸ‘¥ Identified {n_clusters} trader clusters from {len(active_traders)} active traders\\n\")\n",
        "\n",
        "for i in range(n_clusters):\n",
        "    cluster_data = active_traders[active_traders['Cluster'] == i]\n",
        "    print(f\"CLUSTER {i}: {len(cluster_data)} traders ({len(cluster_data)/len(active_traders)*100:.1f}%)\")\n",
        "    print(f\"   Avg PnL: ${cluster_data['Avg_PnL'].mean():,.2f}\")\n",
        "    print(f\"   Win Rate: {cluster_data['Win_Rate'].mean()*100:.1f}%\")\n",
        "    print(f\"   Avg Trade Size: ${cluster_data['Avg_Trade_Size'].mean():,.2f}\")\n",
        "    print(f\"   Avg Sentiment: {cluster_data['Avg_Sentiment'].mean():.1f}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 7: COMPREHENSIVE VISUALIZATIONS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PART 7: GENERATING VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ML Performance Dashboard\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "\n",
        "# 1. Model Accuracy Comparison\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "model_names = list(results.keys())\n",
        "accuracies = [results[m]['accuracy'] for m in model_names]\n",
        "bars = ax1.bar(range(len(model_names)), accuracies,\n",
        "              color=['steelblue', 'coral', 'lightgreen'],\n",
        "              edgecolor='black', linewidth=2)\n",
        "ax1.set_xticks(range(len(model_names)))\n",
        "ax1.set_xticklabels(model_names, rotation=15, ha='right', fontsize=9)\n",
        "ax1.set_ylabel('Accuracy', fontweight='bold')\n",
        "ax1.set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylim([0.3, 0.7])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "for i, (bar, v) in enumerate(zip(bars, accuracies)):\n",
        "    ax1.text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold', fontsize=9)\n",
        "\n",
        "# 2. AUC-ROC Comparison\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "aucs = [results[m]['auc'] for m in model_names]\n",
        "bars = ax2.bar(range(len(model_names)), aucs,\n",
        "              color=['steelblue', 'coral', 'lightgreen'],\n",
        "              edgecolor='black', linewidth=2)\n",
        "ax2.set_xticks(range(len(model_names)))\n",
        "ax2.set_xticklabels(model_names, rotation=15, ha='right', fontsize=9)\n",
        "ax2.set_ylabel('AUC-ROC', fontweight='bold')\n",
        "ax2.set_title('Model AUC-ROC', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylim([0.3, 0.7])\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "for i, (bar, v) in enumerate(zip(bars, aucs)):\n",
        "    ax2.text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold', fontsize=9)\n",
        "\n",
        "# 3. ROC Curves\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "for name in model_names:\n",
        "    fpr, tpr, _ = roc_curve(results[name]['y_test'], results[name]['y_pred_proba'])\n",
        "    ax3.plot(fpr, tpr, label=f\"{name}\\n(AUC={results[name]['auc']:.3f})\", linewidth=2)\n",
        "ax3.plot([0, 1], [0, 1], 'k--', label='Random\\n(AUC=0.5)', linewidth=1.5)\n",
        "ax3.set_xlabel('False Positive Rate', fontweight='bold')\n",
        "ax3.set_ylabel('True Positive Rate', fontweight='bold')\n",
        "ax3.set_title('ROC Curves', fontsize=12, fontweight='bold')\n",
        "ax3.legend(loc='lower right', fontsize=8)\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# 4. Feature Importance\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "top_10 = feature_importance_df.head(10)\n",
        "ax4.barh(range(len(top_10)), top_10['Importance'].values,\n",
        "        color='purple', edgecolor='black', linewidth=1)\n",
        "ax4.set_yticks(range(len(top_10)))\n",
        "ax4.set_yticklabels(top_10['Feature'].values, fontsize=9)\n",
        "ax4.set_xlabel('Importance', fontweight='bold')\n",
        "ax4.set_title('Top 10 Features', fontsize=12, fontweight='bold')\n",
        "ax4.invert_yaxis()\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 5. Confusion Matrix (Best Model)\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "best_model = max(results.keys(), key=lambda k: results[k]['auc'])\n",
        "cm = confusion_matrix(results[best_model]['y_test'], results[best_model]['y_pred'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax5,\n",
        "           xticklabels=['Unprofitable', 'Profitable'],\n",
        "           yticklabels=['Unprofitable', 'Profitable'])\n",
        "ax5.set_title(f'Confusion Matrix\\n({best_model})', fontsize=12, fontweight='bold')\n",
        "ax5.set_ylabel('True', fontweight='bold')\n",
        "ax5.set_xlabel('Predicted', fontweight='bold')\n",
        "\n",
        "# 6. All Metrics Comparison\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.25\n",
        "\n",
        "colors_bar = ['steelblue', 'coral', 'lightgreen']\n",
        "for i, (name, color) in enumerate(zip(model_names, colors_bar)):\n",
        "    values = [\n",
        "        results[name]['accuracy'],\n",
        "        results[name]['precision'],\n",
        "        results[name]['recall'],\n",
        "        results[name]['f1'],\n",
        "        results[name]['auc']\n",
        "    ]\n",
        "    ax6.bar(x + i*width, values, width, label=name,\n",
        "           color=color, edgecolor='black', linewidth=1)\n",
        "\n",
        "ax6.set_ylabel('Score', fontweight='bold')\n",
        "ax6.set_title('All Metrics', fontsize=12, fontweight='bold')\n",
        "ax6.set_xticks(x + width)\n",
        "ax6.set_xticklabels(metrics, fontsize=9)\n",
        "ax6.legend(fontsize=8)\n",
        "ax6.grid(axis='y', alpha=0.3)\n",
        "ax6.set_ylim([0.3, 0.7])\n",
        "\n",
        "plt.suptitle('ðŸ¤– MACHINE LEARNING MODEL PERFORMANCE DASHBOARD',\n",
        "            fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig('ml_performance_complete.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nâœ… ML dashboard saved: 'ml_performance_complete.png'\")\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ‰ COMPLETE ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "best_model_name = max(results.keys(), key=lambda k: results[k]['auc'])\n",
        "best_result = results[best_model_name]\n",
        "\n",
        "print(f\"\"\"\n",
        "ðŸ“Š MACHINE LEARNING RESULTS:\n",
        "\n",
        "Best Model: {best_model_name}\n",
        "â”œâ”€ Accuracy:   {best_result['accuracy']:.4f}\n",
        "â”œâ”€ Precision:  {best_result['precision']:.4f}\n",
        "â”œâ”€ Recall:     {best_result['recall']:.4f}\n",
        "â”œâ”€ F1-Score:   {best_result['f1']:.4f}\n",
        "â”œâ”€ AUC-ROC:    {best_result['auc']:.4f}\n",
        "â””â”€ MCC:        {best_result['mcc']:.4f}\n",
        "\n",
        "Cross-Validation: {best_result['cv_scores'].mean():.4f} (+/- {best_result['cv_scores'].std()*2:.4f})\n",
        "\n",
        "ðŸŽ¯ TOP 3 PREDICTIVE FEATURES:\n",
        "{feature_importance_df.head(3)[['Feature', 'Importance_Pct']].to_string(index=False)}\n",
        "\n",
        "ðŸ“ˆ STATISTICAL VALIDATION:\n",
        "â”œâ”€ Pearson Correlation: {pearson_corr:.4f} (p={pearson_p:.6f}) {'âœ…' if pearson_p < 0.05 else 'âŒ'}\n",
        "â””â”€ ANOVA F-statistic: {f_stat:.2f} (p={anova_p:.6f}) {'âœ…' if anova_p < 0.05 else 'âŒ'}\n",
        "\n",
        "ðŸ‘¥ TRADER CLUSTERING:\n",
        "â””â”€ Identified {n_clusters} distinct trader archetypes\n",
        "\n",
        "ðŸ“ GENERATED FILES:\n",
        "â”œâ”€ complete_analysis_dashboard.png\n",
        "â”œâ”€ timing_heatmaps.png\n",
        "â”œâ”€ ml_performance_complete.png\n",
        "â””â”€ analysis_report.txt\n",
        "\n",
        "âœ… ANALYSIS COMPLETE!\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
